<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Hand Tracking with 3D Model</title>
  <style>
    video { width: 640px; height: 480px; border: 1px solid blue; }
    canvas { border: 1px solid black; }
    #threeCanvas { width: 640px !important; height: 480px !important; border: 1px solid green; }
    body { display: flex; flex-direction: column; align-items: center; }
  </style>
</head>
<body>
  <h3>Hand Tracking with 3D Model</h3>
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas" width="640" height="480"></canvas>
  <canvas id="threeCanvas"></canvas>

  <!-- بارگذاری MediaPipe Hands -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1646424915/hands.js"></script>
  <!-- بارگذاری Three.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js" onload="console.log('Three.js loaded successfully')" onerror="console.error('Failed to load Three.js from CDN')"></script>
  <!-- بارگذاری GLTFLoader -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.134.0/examples/js/loaders/GLTFLoader.js" onload="console.log('GLTFLoader loaded')" onerror="console.error('Failed to load GLTFLoader')"></script>
  <script>
    // چک کردن لود شدن Three.js
    if (typeof THREE === 'undefined') {
      console.error('THREE is not defined.');
      alert('Failed to load Three.js. Check your internet connection.');
      throw new Error('Three.js not loaded');
    }

    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const threeCanvas = document.getElementById('threeCanvas');

    // تنظیم MediaPipe Hands
    const hands = new Hands({
      locateFile: (file) => {
        console.log(`Loading: ${file}`);
        return `https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1646424915/${file}`;
      }
    });

    hands.setOptions({
      maxNumHands: 1, // برای سادگی، فقط یه دست
      modelComplexity: 1,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    // تنظیم Three.js
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(75, 640 / 480, 0.1, 1000);
    const renderer = new THREE.WebGLRenderer({ canvas: threeCanvas });
    renderer.setSize(640, 480);
    camera.position.z = 5;

    // نور محیطی
    const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
    scene.add(ambientLight);
    const directionalLight = new THREE.DirectionalLight(0xffffff, 0.5);
    directionalLight.position.set(0, 1, 1);
    scene.add(directionalLight);

    // لودر برای مدل GLTF
    const loader = new THREE.GLTFLoader();
    let handModel;

    // بارگذاری مدل دست (این یه مدل نمونه‌ست، می‌تونید عوضش کنید)
    loader.load(
      'https://raw.githubusercontent.com/KhronosGroup/glTF-Sample-Models/master/2.0/DamagedHelmet/glTF/DamagedHelmet.gltf', // مدل نمونه
      (gltf) => {
        handModel = gltf.scene;
        handModel.scale.set(2, 2, 2); // مقیاس مدل
        handModel.position.set(0, 0, 0);
        scene.add(handModel);
        console.log('Hand model loaded');
      },
      (xhr) => console.log(`Loading model: ${(xhr.loaded / xhr.total * 100)}%`),
      (error) => console.error('Error loading model:', error)
    );

    hands.onResults((results) => {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      if (results.multiHandLandmarks && handModel) {
        console.log(`Detected ${results.multiHandLandmarks.length} hands`);
        const landmarks = results.multiHandLandmarks[0]; // فقط اولین دست

        // موقعیت مدل رو بر اساس نقطه مچ (landmark 0) تنظیم می‌کنیم
        const wrist = landmarks[0];
        const x = (wrist.x - 0.5) * 10;
        const y = -(wrist.y - 0.5) * 10;
        const z = wrist.z * 10;
        handModel.position.set(x, y, z);

        // رسم نقاط روی کانواس 2D
        for (const point of landmarks) {
          const canvasX = point.x * canvas.width;
          const canvasY = point.y * canvas.height;
          ctx.beginPath();
          ctx.arc(canvasX, canvasY, 5, 0, 2 * Math.PI);
          ctx.fillStyle = 'red';
          ctx.fill();
        }
      } else {
        console.log("No hands detected or model not loaded yet");
      }
    });

    async function startCamera() {
      console.log("Starting camera...");
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        await new Promise((resolve) => {
          video.onloadedmetadata = () => {
            console.log("Video metadata loaded");
            video.play();
            resolve();
          };
        });
        console.log("Camera started");
        if (video.videoWidth === 0 || video.videoHeight === 0) {
          throw new Error("Video dimensions are not ready yet");
        }
      } catch (e) {
        console.error("Camera error:", e);
        alert("Camera failed: " + e.message);
        throw e;
      }
    }

    async function animate() {
      if (video.readyState >= 2) {
        try {
          await hands.send({ image: video });
          console.log("Frame processed");
        } catch (e) {
          console.error("Processing error:", e);
        }
      } else {
        console.log("Video not ready yet, skipping frame");
      }
      renderer.render(scene, camera);
      requestAnimationFrame(animate);
    }

    (async () => {
      console.log("Starting...");
      try {
        await hands.initialize();
        console.log("Hands initialized");
        await startCamera();
        console.log("Starting animation...");
        animate();
      } catch (e) {
        console.error("Error:", e);
        alert("Failed to start: " + e.message);
      }
    })();
  </script>
</body>
</html>
